
require 'abstract.rb'
require 'net/http'
require 'json'
require 'cgi'

module Grabber
  class WikipediaGrabber < AbstractGrabber

    @keyword
    @sections
    @subsections
    @catchwords
    @links
    @numbers
    @sentences

    attr_reader :keyword

    def features
      return [:sentence, :catchword, :link, :number, :topics]
    end

    def initialize(keyword)
      #start_time = Time.now

      @keyword = keyword
      esc_keyword = CGI.escape(keyword)
      uri = URI.parse("http://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&format=txt&titles=#{esc_keyword}")
      doc = Net::HTTP.get(uri)

      json = doc.to_s
      #json = JSON.parse(doc)
      #json = json["query"]["pages"]
      #json = json[json.keys.first]["revisions"][0]["*"]
      #old regexp: @sections = json.scan(/^==([A-Z][a-zA-Z|\s]*)/)

      @sections = json.scan(/^==\s?([A-Z][a-zA-Z|\s]*).*==$/)
      
      @subsections = json.scan(/^===\s?([A-Z][a-zA-Z|\s]*).*===$/)
      @sections = normalize_topics @sections
      @subsections = normalize_topics @subsections
      @catchwords = json.scan(/\[\[([^:\]|]*)\]\]/)
      @catchwords.flatten!
      @links = json.scan(/\[(http:[^\s]*)/)
      @numbers = json.scan(/\d+[\.]?\d+/)
      @sentences = json.scan(/[\.\?\!\n]([A-Z][^|{\}\*\=]*[\.\?\!])/).flatten!
      @sentences.collect! do |sentence|
          sentence.delete!("[]'\n")
      end
      @sentences.compact!
      @sentences = split_sentences @sentences

      #puts "sections: #{@sections.inspect}"
      #puts "subsections: #{@subsections.inspect}"
      #puts "keywords: #{@keywords.inspect}"
      #puts "links: #{@links.inspect}"
      #puts "numbers: #{@numbers.inspect}"
      #puts "sentences: #{@sentences.inspect}"
      #end_time = Time.now
      #puts end_time-start_time
    end

    def sentence
      @sentences.pop
    end

    def catchword
      @catchwords.pop
    end

    def link
      @links.pop[0]
    end

    def number
      @numbers.pop
    end

    def topics
      @sections + @subsections
    end

    def good_keyword?
      if topics.length > 5
        true
      else
        false
      end
    end

    def normalize_topics(topics)
      topics.flatten!
      topics.compact!
      topics.collect! { |item|
        item.strip
      }
      bad_topics = ["See also", "References", "Further reading", "External links"]
      bad_topics.each do |topic|
        topics.delete(topic)
        #puts "topics after deletion of #{topic}: #{topics.inspect}"
      end
      topics.uniq!
      topics
    end

    def split_sentences(sentences)
      new_sentences = Array.new
      sentences.each { |item|
        new_sentences.concat item.split(". ")
      }
      new_sentences
    end

  end
end